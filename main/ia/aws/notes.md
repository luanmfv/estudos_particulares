Amazon Inspector √© um servi√ßo automatizado de avalia√ß√£o de seguran√ßa da AWS. Ele:

Faz varredura de vulnerabilidades em inst√¢ncias do Amazon EC2.

Avalia imagens armazenadas no Amazon Elastic Container Registry (ECR) em busca de falhas de seguran√ßa conhecidas.

Gera recomenda√ß√µes de corre√ß√£o para reduzir riscos.

---------------------------------------------------------------------------------------------------------------------

Engenharia de atributos (Feature Engineering):

Consiste em criar novas vari√°veis (atributos) a partir dos dados existentes, transformando ou combinando colunas para enriquecer o conjunto de treinamento.

Exemplo: extrair "dia da semana" a partir de uma data, ou criar uma vari√°vel "IMC" a partir de peso e altura.

Coleta de dados:

Ao coletar mais dados, √© poss√≠vel incluir novas vari√°veis que antes n√£o existiam no conjunto.

Isso aumenta a diversidade e a representatividade do dataset, melhorando o desempenho do modelo.


---------------------------------------------------------------------------------------------------------------------

Amazon Transcribe √© o servi√ßo da AWS para converter fala em texto.

Ele permite criar um modelo de linguagem personalizado (Custom Language Model), que √© treinado com vocabul√°rio espec√≠fico de um dom√≠nio ou setor (ex.: financeiro, m√©dico, jur√≠dico, call center etc.).

Isso melhora a precis√£o da transcri√ß√£o porque o modelo aprende termos t√©cnicos, nomes de produtos, siglas e express√µes t√≠picas da empresa.

---------------------------------------------------------------------------------------------------------------------

AWS IAM

O IAM √© respons√°vel por autentica√ß√£o e autoriza√ß√£o (quem pode acessar o qu√™).

Barreiras de Prote√ß√£o para Amazon Bedrock 

Bedrock permite configurar guardrails para bloquear certos t√≥picos (ex.: viol√™ncia, pol√≠tica, etc.).

Na AWS, Guardrail (barreira de prote√ß√£o) √© um conjunto de regras e controles pr√©-definidos que servem para limitar, monitorar e orientar o comportamento de um servi√ßo ou aplica√ß√£o, garantindo seguran√ßa, conformidade e uso adequado.

---------------------------------------------------------------------------------------------------------------------

GCP significa Google Cloud Platform.

√â a plataforma de computa√ß√£o em nuvem do Google, que oferece v√°rios servi√ßos para empresas e desenvolvedores, como:

Computa√ß√£o: m√°quinas virtuais (Compute Engine), Kubernetes (GKE), fun√ß√µes serverless (Cloud Functions).

Armazenamento: bancos de dados SQL, NoSQL (Firestore, Bigtable), armazenamento de arquivos (Cloud Storage).

Redes: balanceadores de carga, CDN, VPCs.

IA e Machine Learning: APIs de vis√£o, tradu√ß√£o, modelos de IA generativa (Vertex AI).

Ferramentas de dados: BigQuery (an√°lise de dados), Dataflow, Pub/Sub.

---------------------------------------------------------------------------------------------------------------------

ITIL (Information Technology Infrastructure Library) √© um conjunto de boas pr√°ticas para gest√£o de servi√ßos de TI.
Ele ajuda empresas a organizarem processos de suporte, incidentes, mudan√ßas, entregas e melhorias cont√≠nuas.

Principais pontos:

Service Desk: central de atendimento.

Gest√£o de Incidentes: resolver falhas rapidamente.

Gest√£o de Problemas: identificar causa raiz.

Gest√£o de Mudan√ßas: controlar altera√ß√µes em sistemas.

Gest√£o de Configura√ß√£o e Ativos: mapear recursos de TI.

üëâ Em resumo: ITIL √© um guia de como gerir TI de forma eficiente e organizada.

---------------------------------------------------------------------------------------------------------------------

Quando uma empresa treina ou personaliza um modelo de base (FM) do zero usando seus pr√≥prios dados:

Custos mais altos (D):

Treinar modelos grandes exige muita infraestrutura computacional, armazenamento e energia.

Manuten√ß√£o cont√≠nua do modelo tamb√©m aumenta os custos.

Maior complexidade de implementa√ß√£o (E):

√â necess√°rio lidar com pr√©-processamento de dados, ajustes de hiperpar√¢metros, valida√ß√£o, pipelines de treinamento e escalabilidade.

O processo √© mais t√©cnico e trabalhoso do que apenas usar um FM pr√©-treinado.

---------------------------------------------------------------------------------------------------------------------
Cart√µes de modelo do SageMaker (Model Cards) s√£o documentos estruturados que permitem registrar informa√ß√µes importantes sobre cada modelo de ML, como:

Uso pretendido do modelo

Classifica√ß√µes de risco

Detalhes do treinamento (conjuntos de dados, algoritmos, par√¢metros)

Resultados de avalia√ß√£o e m√©tricas

Isso ajuda propriet√°rios e equipes de ML a manter transpar√™ncia, rastreabilidade e conformidade ao gerenciar modelos.

---------------------------------------------------------------------------------------------------------------------

op√ß√µes de infer√™ncia do Amazon SageMaker AI e ordene-as da MENOR √† MAIOR lat√™ncia.

Infer√™ncia em tempo real:

Projetada para responder imediatamente a solicita√ß√µes de predi√ß√£o.

Lat√™ncia √© muito baixa, pois o endpoint est√° sempre ativo.

Infer√™ncia ass√≠ncrona:

Processa solicita√ß√µes que n√£o precisam de resposta imediata.

Lat√™ncia √© maior que a em tempo real, pois o job √© enfileirado e processado conforme recursos ficam dispon√≠veis.

Transforma√ß√£o em lote (Batch Transform):

Executa predi√ß√µes em grandes volumes de dados de uma vez.

N√£o √© para respostas imediatas ‚Üí lat√™ncia √© a maior, pois processa dados em lote, de forma offline.



---------------------------------------------------------------------------------------------------------------------


Few-shot prompting: voc√™ fornece ao modelo alguns exemplos de como a tarefa deve ser realizada (ex.: descri√ß√µes de produtos bem escritas no estilo do site).

O modelo aprende o padr√£o a partir desses exemplos e gera novos textos de forma consistente com o estilo e tom desejados.

√â a t√©cnica com menor esfor√ßo operacional porque:

N√£o exige treinar ou ajustar o modelo (como no fine-tuning).

Basta fornecer exemplos diretamente no prompt.

---------------------------------------------------------------------------------------------------------------------

ML significa Machine Learning, ou Aprendizado de M√°quina em portugu√™s.

√â uma √°rea da intelig√™ncia artificial onde computadores aprendem padr√µes a partir de dados e fazem previs√µes ou decis√µes sem serem explicitamente programados para cada regra.

Como funciona basicamente:

Coleta de dados: textos, imagens, n√∫meros, √°udio, etc.

Treinamento do modelo: o computador aprende padr√µes e rela√ß√µes nos dados.

Teste e valida√ß√£o: verifica se o modelo consegue fazer boas previs√µes com dados novos.

Infer√™ncia: o modelo j√° treinado √© usado para fazer previs√µes ou tomar decis√µes.

Exemplos de ML no dia a dia:

Recomenda√ß√£o de filmes na Netflix.

Previs√£o do tempo.

Detec√ß√£o de fraudes em cart√µes de cr√©dito.

Tradu√ß√£o autom√°tica de idiomas.

Reconhecimento de fala e imagem.

---------------------------------------------------------------------------------------------------------------------

Amazon Bedrock permite usar modelos de IA generativa pr√©-treinados sem precisar:

Treinar ou ajustar modelos (ou seja, sem fine-tuning).

Gerenciar infraestrutura de ML.

Ele oferece modelos de texto, imagem e multim√≠dia de fornecedores como AI21, Anthropic, Stability AI, etc.

No caso da empresa de turismo: basta chamar o modelo via API para gerar imagens de fundo para marketing.

---------------------------------------------------------------------------------------------------------------------

FM significa Foundation Models (Modelos de Funda√ß√£o) no contexto de IA e ML.

S√£o modelos de grande escala treinados em enormes volumes de dados que servem como base para muitas tarefas diferentes, como texto, imagem, √°udio ou multim√≠dia.

Caracter√≠sticas principais:

Pr√©-treinados em larga escala:

Aprendem padr√µes gerais de linguagem, imagens ou som a partir de enormes datasets.

Vers√°teis:

Podem ser usados diretamente para tarefas diversas (zero-shot ou few-shot) ou personalizados para dom√≠nios espec√≠ficos.

Exemplos:

GPT (texto)

BERT (texto)

DALL¬∑E, Stable Diffusion (imagens)

Diferen√ßa entre FM e modelos tradicionais:

Modelos tradicionais s√£o treinados para uma tarefa espec√≠fica (ex.: prever pre√ßo de casas).

FMs s√£o gen√©ricos e podem ser adaptados para v√°rias tarefas com menos esfor√ßo de treinamento.

---------------------------------------------------------------------------------------------------------------------

Limita√ß√£o principal da IA generativa:

Mesmo sendo poderosa para criar texto, imagens ou √°udio, os modelos podem gerar conte√∫dos incorretos, enviesados ou inapropriados.

Por isso, sempre √© necess√°ria revis√£o humana antes de publicar conte√∫do em um site.

---------------------------------------------------------------------------------------------------------------------

Amazon Rekognition Custom Labels:

Permite criar modelos de vis√£o computacional personalizados para classificar imagens em categorias espec√≠ficas.

Ideal para identificar r√≥tulos personalizados de produtos com base em imagens hist√≥ricas.

Fornecer imagens rotuladas:

O modelo precisa de exemplos de treinamento com categorias definidas para aprender a classificar corretamente novas imagens.

Apenas imagens n√£o rotuladas n√£o permitem treinar o modelo de forma supervisionada.

---------------------------------------------------------------------------------------------------------------------

Ajuste fino baseado em instru√ß√µes (instruction fine-tuning) √© uma t√©cnica usada para ensinar um modelo de linguagem a responder de forma desejada a determinados prompts ou perguntas.

Para isso, o modelo precisa de pares de entrada e sa√≠da de texto:

Prompt (entrada): a instru√ß√£o ou pergunta que voc√™ quer que o modelo entenda.

Resposta (sa√≠da): o texto que o modelo deve gerar ao receber aquele prompt.

{"prompt": "Explique o que √© machine learning.", "response": "Machine learning √© uma √°rea da intelig√™ncia artificial onde computadores aprendem padr√µes a partir de dados."}

---------------------------------------------------------------------------------------------------------------------

Amazon Textract √© um servi√ßo da AWS especializado em extrair texto e dados de documentos, incluindo:

Faturas, recibos, contratos, formul√°rios.

Suporta texto digitado e manuscrito.

Funciona com documentos em imagens (PNG, JPEG) ou PDFs.

Ele vai al√©m do OCR tradicional porque tamb√©m consegue identificar tabelas, campos de formul√°rio e relacionamentos entre dados.

---------------------------------------------------------------------------------------------------------------------

Sobreajuste ocorre quando um modelo aprende demais os detalhes e ru√≠dos dos dados de treinamento, ao ponto de:

Ter alta acur√°cia nos dados de treinamento.

Ter baixa acur√°cia em dados novos ou de teste, porque n√£o generaliza bem.

√â um problema comum em modelos muito complexos ou quando h√° poucos dados de treinamento.

O sobreajuste ocorre quando um modelo aprende com os dados de treinamento e n√£o consegue ter um bom desempenho quando recebe novos dados. Esse fator explica por que o modelo tem alta acur√°cia nos dados de treinamento e baixa acur√°cia nos dados de teste.

---------------------------------------------------------------------------------------------------------------------

LLM significa Large Language Model (Modelo de Linguagem de Grande Escala).

√â um modelo de intelig√™ncia artificial treinado para entender e gerar texto em linguagem natural.

Caracter√≠sticas principais:

Treinado em grandes volumes de dados textuais

Pode ser textos da internet, livros, artigos, c√≥digos, etc.

Gera respostas coerentes e contextualizadas

Pode escrever textos, resumir conte√∫dos, responder perguntas, traduzir idiomas, criar di√°logos e at√© gerar c√≥digo.

Capaz de generalizar

Mesmo sem ser treinado especificamente para uma tarefa, consegue realizar diversas fun√ß√µes (zero-shot ou few-shot).

Exemplos de LLMs:

GPT (OpenAI)

BERT (Google)

Claude (Anthropic)

LLaMA (Meta)

Resumo pr√°tico:
Um LLM √© um modelo de IA que entende e cria texto, usando aprendizado em larga escala para responder perguntas, gerar conte√∫do ou realizar tarefas de linguagem natural.



---------------------------------------------------------------------------------------------------------------------

RAG (Retrieval-Augmented Generation) √© uma t√©cnica que permite ao modelo de linguagem acessar informa√ß√µes externas (bases de conhecimento, documentos, FAQs, bancos de dados) para gerar respostas mais precisas e consistentes.

Como funciona:

O modelo recebe uma pergunta ou prompt.

Busca em fontes externas documentos ou trechos relevantes.

Usa essas informa√ß√µes para gerar a resposta final.

Vantagem:

Requer pouco esfor√ßo de desenvolvimento, porque voc√™ n√£o precisa treinar ou ajustar o modelo, apenas conecta ele a uma base de dados ou sistema de recupera√ß√£o.

---------------------------------------------------------------------------------------------------------------------
ROUGE √© uma m√©trica de avalia√ß√£o autom√°tica de texto gerado.

√â usada para comparar o texto gerado pelo modelo com textos de refer√™ncia ou respostas corretas, medindo sobreposi√ß√£o de n-gramas, palavras ou frases.

Muito utilizada em tarefas de resumo autom√°tico, tradu√ß√£o e gera√ß√£o de texto.

---------------------------------------------------------------------------------------------------------------------

Amazon SageMaker JumpStart oferece modelos de base (FM) de c√≥digo aberto prontos para uso, incluindo modelos de linguagem, vis√£o computacional e mais.

Permite avaliar, ajustar ou implantar modelos rapidamente sem precisar treinar do zero.

No caso da empresa: √© poss√≠vel usar um FM de linguagem para avaliar contratos e identificar conformidade com regras e pol√≠ticas.

SageMaker JumpStart √© um recurso do SageMaker AI que fornece modelos de c√≥digo aberto pr√©-treinados para voc√™ usar. O SageMaker JumpStart oferece FMs que podem ser usados para casos de uso de resumo.

---------------------------------------------------------------------------------------------------------------------

Voc√™ pode usar o IAM para controlar o acesso a recursos da AWS por meio de usu√°rios, perfis e pol√≠ticas. Voc√™ pode usar o IAM para controlar quais usu√°rios ou servi√ßos t√™m acesso ao Amazon Bedrock. Voc√™ pode usar o IAM para controlar quais a√ß√µes o usu√°rio ou servi√ßo pode realizar. Voc√™ pode usar o IAM para proteger o acesso ao Amazon Bedrock.

---------------------------------------------------------------------------------------------------------------------


AWS CloudTrail √© o servi√ßo da AWS respons√°vel por registrar todas as chamadas de API feitas nos servi√ßos da AWS.

Ele fornece logs detalhados que incluem:

Qual API foi chamada

Quem (usu√°rio ou fun√ß√£o) fez a chamada

Quando a chamada ocorreu

Eventualmente detalhes adicionais sobre par√¢metros e respostas

Esses logs s√£o essenciais para:

Auditoria e conformidade

Rastreamento de problemas de seguran√ßa

Monitoramento de uso e opera√ß√µes

√â poss√≠vel usar o CloudTrail para monitorar e registrar em log as chamadas de API em contas da AWS. Os registros do CloudTrail cont√™m o evento da API, o usu√°rio que fez a chamada de API e a hora em que a chamada foi feita.

---------------------------------------------------------------------------------------------------------------------






















